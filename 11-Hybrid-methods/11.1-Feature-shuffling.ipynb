{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection by Random Shuffling\n",
    "\n",
    "A popular method of feature selection consists of randomly shuffling the values of a specific variable and determining how that permutation affects the performance metric of the machine learning algorithm. In other words, the idea is to shuffle the values of each feature, one feature at a time, and measure how much the permutation (or shuffling of its values) decreases the accuracy, or the roc_auc, or the mse of the machine learning model (or any other performance metric!). If the variables are important, a random permutation of their values will dramatically decrease any of these metrics. Contrarily, the permutation or shuffling of values should have little to no effect on the model performance metric we are assessing.\n",
    "\n",
    "The procedure goes more or less like this:\n",
    "\n",
    "- Build a machine learning model and store its performance metrics.\n",
    "\n",
    "- Shuffle 1 feature, and make a new prediction using the previous model.\n",
    "\n",
    "- Determine the performance of this prediction.\n",
    "\n",
    "- Determine the change in the performance of the prediction with the shuffled feature compared to the original one.\n",
    "\n",
    "- Repeat for each feature.\n",
    "\n",
    "To select features, we chose those that induced a decrease in model performance beyond an arbitrarily set threshold.\n",
    "\n",
    "I will demonstrate how to select features based on random shuffling using a regression and classification problem. \n",
    "\n",
    "**Note** For the demonstration, I will continue to use Random Forests, but this selection procedure can be used with any machine learning algorithm. In fact, the importance of the features is determined specifically for the algorithm used. Therefore, different algorithms may return different subsets of important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 109)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('../dataset_2.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>var_107</th>\n",
       "      <th>var_108</th>\n",
       "      <th>var_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.532710</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>17.982476</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.349910</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079066</td>\n",
       "      <td>6.748819</td>\n",
       "      <td>2.941445</td>\n",
       "      <td>18.360496</td>\n",
       "      <td>17.726613</td>\n",
       "      <td>7.774031</td>\n",
       "      <td>1.473441</td>\n",
       "      <td>1.973832</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>2.541417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.821374</td>\n",
       "      <td>12.098722</td>\n",
       "      <td>13.309151</td>\n",
       "      <td>4.125599</td>\n",
       "      <td>1.045386</td>\n",
       "      <td>1.832035</td>\n",
       "      <td>1.833494</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>8.652883</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>7.795290</td>\n",
       "      <td>3.557890</td>\n",
       "      <td>17.383378</td>\n",
       "      <td>15.193423</td>\n",
       "      <td>8.263673</td>\n",
       "      <td>1.878108</td>\n",
       "      <td>0.567939</td>\n",
       "      <td>1.018818</td>\n",
       "      <td>1.416433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938776</td>\n",
       "      <td>7.952752</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>3.459267</td>\n",
       "      <td>1.935782</td>\n",
       "      <td>0.621463</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>0.344948</td>\n",
       "      <td>9.937850</td>\n",
       "      <td>11.691283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861487</td>\n",
       "      <td>6.130886</td>\n",
       "      <td>3.401064</td>\n",
       "      <td>15.850471</td>\n",
       "      <td>14.620599</td>\n",
       "      <td>6.849776</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>1.959183</td>\n",
       "      <td>1.575493</td>\n",
       "      <td>1.857893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.020690</td>\n",
       "      <td>9.900544</td>\n",
       "      <td>17.869637</td>\n",
       "      <td>4.366715</td>\n",
       "      <td>1.973693</td>\n",
       "      <td>2.026012</td>\n",
       "      <td>2.853025</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>11.816859</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340944</td>\n",
       "      <td>7.240058</td>\n",
       "      <td>2.417235</td>\n",
       "      <td>15.194609</td>\n",
       "      <td>13.553772</td>\n",
       "      <td>7.229971</td>\n",
       "      <td>0.835158</td>\n",
       "      <td>2.234482</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>2.700606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.909506</td>\n",
       "      <td>10.576516</td>\n",
       "      <td>0.934191</td>\n",
       "      <td>3.419572</td>\n",
       "      <td>1.871438</td>\n",
       "      <td>3.340811</td>\n",
       "      <td>1.868282</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>13.585620</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>...</td>\n",
       "      <td>2.738095</td>\n",
       "      <td>6.565509</td>\n",
       "      <td>4.341414</td>\n",
       "      <td>15.893832</td>\n",
       "      <td>11.929787</td>\n",
       "      <td>6.954033</td>\n",
       "      <td>1.853364</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>2.599562</td>\n",
       "      <td>0.811364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1      var_2      var_3     var_4     var_5     var_6     var_7  \\\n",
       "0  4.532710   3.280834  17.982476  4.404259  2.349910  0.603264  2.784655   \n",
       "1  5.821374  12.098722  13.309151  4.125599  1.045386  1.832035  1.833494   \n",
       "2  1.938776   7.952752   0.972671  3.459267  1.935782  0.621463  2.338139   \n",
       "3  6.020690   9.900544  17.869637  4.366715  1.973693  2.026012  2.853025   \n",
       "4  3.909506  10.576516   0.934191  3.419572  1.871438  3.340811  1.868282   \n",
       "\n",
       "      var_8      var_9     var_10  ...   var_100   var_101   var_102  \\\n",
       "0  0.323146  12.009691   0.139346  ...  2.079066  6.748819  2.941445   \n",
       "1  0.709090   8.652883   0.102757  ...  2.479789  7.795290  3.557890   \n",
       "2  0.344948   9.937850  11.691283  ...  1.861487  6.130886  3.401064   \n",
       "3  0.674847  11.816859   0.011151  ...  1.340944  7.240058  2.417235   \n",
       "4  0.439865  13.585620   1.153366  ...  2.738095  6.565509  4.341414   \n",
       "\n",
       "     var_103    var_104   var_105   var_106   var_107   var_108   var_109  \n",
       "0  18.360496  17.726613  7.774031  1.473441  1.973832  0.976806  2.541417  \n",
       "1  17.383378  15.193423  8.263673  1.878108  0.567939  1.018818  1.416433  \n",
       "2  15.850471  14.620599  6.849776  1.098210  1.959183  1.575493  1.857893  \n",
       "3  15.194609  13.553772  7.229971  0.835158  2.234482  0.946170  2.700606  \n",
       "4  15.893832  11.929787  6.954033  1.853364  0.511027  2.599562  0.811364  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit and data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this method, it is necessary to reset the indeces of the returned \n",
    "# datasets\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ML algo with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc score:  0.690997114685582\n",
      "test auc score:  0.6857035229040285\n"
     ]
    }
   ],
   "source": [
    "# The first step to determine feature importance by feature shuffling\n",
    "# is to build the machine learning model for which we want to\n",
    "# select features\n",
    "\n",
    "# In this case, I will build Random Forests, but remember that\n",
    "# you can use this procedure with any other machine learning algorithm.\n",
    "\n",
    "# I build few and shallow trees to avoid overfitting\n",
    "rf = RandomForestClassifier(n_estimators=50,\n",
    "                            max_depth=2,\n",
    "                            random_state=2909,\n",
    "                            n_jobs=4)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print roc-auc in train and testing sets\n",
    "print('train auc score: ',\n",
    "      roc_auc_score(y_train, (rf.predict_proba(X_train.fillna(0)))[:, 1]))\n",
    "print('test auc score: ',\n",
    "      roc_auc_score(y_test, (rf.predict_proba(X_test.fillna(0)))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle features and asses performance drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, I will shuffle one by one, each feature of the dataset\n",
    "\n",
    "# then I use the dataset with the shuffled variable to make predictions\n",
    "# with the random forests I trained in the previous cell\n",
    "\n",
    "# overall train roc-auc: using all the features\n",
    "train_roc = roc_auc_score(y_train, (rf.predict_proba(X_train))[:, 1])\n",
    "\n",
    "# list to capture the performance shift\n",
    "performance_shift = []\n",
    "\n",
    "# selection  logic\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    X_train_c = X_train.copy()\n",
    "\n",
    "    # shuffle individual feature\n",
    "    X_train_c[feature] = X_train_c[feature].sample(\n",
    "        frac=1, random_state=10).reset_index(drop=True)\n",
    "\n",
    "    # make prediction with shuffled feature and calculate roc-auc\n",
    "    shuff_roc = roc_auc_score(y_train, rf.predict_proba(X_train_c)[:, 1])\n",
    "    \n",
    "    drift = train_roc - shuff_roc\n",
    "\n",
    "    # save the drop in roc-auc\n",
    "    performance_shift.append(drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " -9.919140466640997e-05,\n",
       " -5.777064524881137e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -3.334693591705573e-05,\n",
       " 8.796265542265758e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.2864223244933868e-05,\n",
       " -6.957465160806198e-05,\n",
       " 4.371055238927557e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.015497219959881292,\n",
       " -0.00012937667354617766,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0013551709383483601,\n",
       " 0.0,\n",
       " -7.38081844428029e-05,\n",
       " 0.0,\n",
       " 1.2296120844856873e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0015281413151823076,\n",
       " 2.6043867067171433e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.001336418904640313,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00015224539098712686,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.020099856532177e-06,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.17743806627535e-05,\n",
       " 0.0,\n",
       " 0.0017028464517550024,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.07156079421237771,\n",
       " 0.0,\n",
       " -0.00015256447891842662,\n",
       " 4.3209449511305564e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00018709114134207727,\n",
       " -8.323251390618402e-05,\n",
       " 0.00010579113180830824,\n",
       " 1.5033086339877322e-05,\n",
       " 0.0,\n",
       " 3.216945650863501e-05,\n",
       " 0.008743101448133728,\n",
       " 0.0035736702283486466,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.00010268788932177308,\n",
       " 8.200559833926313e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.2970250277133388e-05,\n",
       " 0.0,\n",
       " 0.0002834152488229158,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.0003512281755146951,\n",
       " 0.0,\n",
       " -0.00023584867608106297,\n",
       " 0.0,\n",
       " 0.0006831133305189585,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0010592460943602555,\n",
       " 4.597338018363928e-05,\n",
       " -4.512173000126296e-06,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0003018279707167615,\n",
       " -5.0818123703777474e-05,\n",
       " 0.0003170565545920212,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.00023036126250230993,\n",
       " 0.0,\n",
       " 2.3549588167304236e-06,\n",
       " 3.656702750509666e-05,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0066017899781302125,\n",
       " 0.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le't have a look at our list of performances\n",
    "performance_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_1    0.000000\n",
       "var_2   -0.000099\n",
       "var_3   -0.000058\n",
       "var_4    0.000000\n",
       "var_5    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I will transform the list into a pandas Series\n",
    "# for easy manipulation\n",
    "\n",
    "feature_importance = pd.Series(performance_shift)\n",
    "\n",
    "# add variable names in the index\n",
    "feature_importance.index = X_train.columns\n",
    "\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_55     0.071561\n",
       "var_16     0.015497\n",
       "var_69     0.008743\n",
       "var_108    0.006602\n",
       "var_70     0.003574\n",
       "             ...   \n",
       "var_63    -0.000187\n",
       "var_102   -0.000230\n",
       "var_86    -0.000236\n",
       "var_84    -0.000351\n",
       "var_30    -0.001528\n",
       "Length: 108, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I will sort the dataframe according to the drop in performance\n",
    "# caused by feature shuffling\n",
    "\n",
    "feature_importance.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_55     0.071561\n",
       "var_16     0.015497\n",
       "var_69     0.008743\n",
       "var_108    0.006602\n",
       "var_70     0.003574\n",
       "var_48     0.001703\n",
       "var_21     0.001355\n",
       "var_34     0.001336\n",
       "var_91     0.001059\n",
       "var_88     0.000683\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualise the top 10 features that caused the major drop\n",
    "# in the roc-auc (aka model performance)\n",
    "\n",
    "feature_importance.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original number of features (rows in this case)\n",
    "feature_importance.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features that cause a drop in performance\n",
    "# when shuffled\n",
    "\n",
    "feature_importance[feature_importance>0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 30 out of the 108 features caused a drop in the performance of the random forests when their values were permuted. This means that we could select those features and discard the rest, and should keep the original random forest performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var_7', 'var_11', 'var_13', 'var_16', 'var_21', 'var_25', 'var_31',\n",
       "       'var_34', 'var_38', 'var_43', 'var_46', 'var_48', 'var_55', 'var_58',\n",
       "       'var_65', 'var_66', 'var_68', 'var_69', 'var_70', 'var_73', 'var_74',\n",
       "       'var_79', 'var_88', 'var_91', 'var_92', 'var_96', 'var_98', 'var_104',\n",
       "       'var_105', 'var_108'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the important features\n",
    "\n",
    "feature_importance[feature_importance>0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auc score:  0.6954703746877449\n",
      "test auc score:  0.6932896839648326\n"
     ]
    }
   ],
   "source": [
    "# Now let's build a random forests only with the selected features\n",
    "\n",
    "# capture the selected features\n",
    "selected_features = feature_importance[feature_importance > 0].index\n",
    "\n",
    "# train a new random forests using only the selected features\n",
    "rf = RandomForestClassifier(n_estimators=50,\n",
    "                            max_depth=2,\n",
    "                            random_state=2909,\n",
    "                            n_jobs=4)\n",
    "\n",
    "rf.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# print roc-auc in train and testing sets\n",
    "print(\n",
    "    'train auc score: ',\n",
    "    roc_auc_score(y_train, (rf.predict_proba(X_train[selected_features]))[:,\n",
    "                                                                          1]))\n",
    "print(\n",
    "    'test auc score: ',\n",
    "    roc_auc_score(y_test, (rf.predict_proba(X_test[selected_features]))[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the random forests with the selected features show a similar performance (or even slightly higher) to the random forests built using all of the features. And it provides a simpler, faster and more reliable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('../houseprice.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 36), (438, 36))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['Id', 'SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this method, it is necessary to reset the indeces of the returned \n",
    "# datasets\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ML algo with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse:  34125.46855017603\n",
      "train r2:  0.8090829266232026\n",
      "\n",
      "test rmse:  39164.18326517837\n",
      "test r2:  0.7740705281238518\n"
     ]
    }
   ],
   "source": [
    "# The first step to determine feature importance by feature shuffling\n",
    "# is to build the machine learning model for which we want to\n",
    "# select features\n",
    "\n",
    "# In this case, I will build Random Forests, but remember that\n",
    "# you can use this procedure for any other machine learning algorithm\n",
    "\n",
    "# I build few and shallow trees to avoid overfitting\n",
    "rf = RandomForestRegressor(n_estimators=100,\n",
    "                           max_depth=3,\n",
    "                           random_state=2909,\n",
    "                           n_jobs=4)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print performance metrics\n",
    "print('train rmse: ',\n",
    "      mean_squared_error(y_train, rf.predict(X_train), squared=False))\n",
    "print('train r2: ', r2_score(y_train, (rf.predict(X_train))))\n",
    "print()\n",
    "print('test rmse: ',\n",
    "      mean_squared_error(y_test, rf.predict(X_test), squared=False))\n",
    "print('test r2: ', r2_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle features and asses performance drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, I will shuffle one by one, each feature of the dataset\n",
    "# and then use the dataset with the shuffled variable to make predictions\n",
    "# using the random forests I trained in the previous cell\n",
    "\n",
    "# overall train rmse: using all the features\n",
    "train_rmse = mean_squared_error(y_train, rf.predict(X_train), squared=False)\n",
    "\n",
    "# list to capture the performance shift\n",
    "performance_shift = []\n",
    "\n",
    "# for each feature:\n",
    "for feature in X_train.columns:\n",
    "    \n",
    "    X_train_c = X_train.copy()\n",
    "\n",
    "    # shuffle individual feature\n",
    "    X_train_c[feature] = X_train_c[feature].sample(frac=1, random_state=11).reset_index(\n",
    "        drop=True)\n",
    "\n",
    "    # make prediction with shuffled feature and calculate roc-auc\n",
    "    shuff_rmse = mean_squared_error(y_train, rf.predict(X_train_c), squared=False)\n",
    "    \n",
    "    drift = train_rmse - shuff_rmse \n",
    "\n",
    "    # store the drop in roc-auc\n",
    "    performance_shift.append(drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         0.000000\n",
       "LotFrontage      -45.751607\n",
       "LotArea         -390.252300\n",
       "OverallQual   -42772.508176\n",
       "OverallCond       -6.967475\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I will transform the list into a pandas Series\n",
    "# for easy manipulation\n",
    "\n",
    "feature_importance = pd.Series(performance_shift)\n",
    "\n",
    "# add variable names in the index\n",
    "feature_importance.index = X_train.columns\n",
    "\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note here that when looking at the rmse, the smaller the better.\n",
    "\n",
    "# as we do original_rmse - shuffled_data_rmse\n",
    "\n",
    "# if the feature was important, the shuffled data would increase the rsme\n",
    "\n",
    "# thus, we are looking for negative values here\n",
    "\n",
    "# number of features that cause a drop in performance\n",
    "# when shuffled\n",
    "\n",
    "feature_importance[feature_importance<0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "       'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
       "       'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath',\n",
       "       'BsmtHalfBath', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd',\n",
       "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
       "       'OpenPorchSF', 'EnclosedPorch', 'ScreenPorch', 'MoSold', 'YrSold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the variable names\n",
    "\n",
    "feature_importance[feature_importance<0].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's compare the performance of a random forest\n",
    "# built only using the selected features\n",
    "\n",
    "# slice the data\n",
    "feat = feature_importance[feature_importance<0].index\n",
    "\n",
    "X_train = X_train[feat]\n",
    "X_test = X_test[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 29), (1022, 29))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse:  34160.71788974547\n",
      "train r2:  0.8086883136434085\n",
      "\n",
      "test rmse:  39509.02025977596\n",
      "test r2:  0.7700744366138201\n"
     ]
    }
   ],
   "source": [
    "# build and evaluate the model\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100,\n",
    "                           max_depth=3,\n",
    "                           random_state=2909,\n",
    "                           n_jobs=4)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# print performance metrics\n",
    "print('train rmse: ', mean_squared_error(\n",
    "    y_train, rf.predict(X_train), squared=False))\n",
    "print('train r2: ', r2_score(y_train, (rf.predict(X_train))))\n",
    "print()\n",
    "print('test rmse: ', mean_squared_error(\n",
    "    y_test, rf.predict(X_test), squared=False))\n",
    "print('test r2: ', r2_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with less features shows similar performance to that with all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
