{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quasi-constant features\n",
    "\n",
    "Quasi-constant features are those that show the same value for the great majority of the observations of the dataset. In general, these features provide little, if any, information that allows a machine learning model to discriminate or predict a target. But there can be exceptions. So you should be careful when removing these type of features.\n",
    "\n",
    "Identifying and removing quasi-constant features, is an easy first step towards feature selection and more interpretable machine learning models.\n",
    "\n",
    "Here, I will demonstrate how to identify quasi-constant features using a dataset that I created for this course. \n",
    "\n",
    "To identify quasi-constant features, we can use the VarianceThreshold from Scikit-learn, or we can code it ourselves. If we use the VarianceThreshold, all our variables need to be numerical. If we code it manually however, we can apply the code to both numerical and categorical variables.\n",
    "\n",
    "I will show 2 snippets of code, 1 where I use the VarianceThreshold and 1 manually coded alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 301)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "# (feel free to write some code to explore the dataset and become\n",
    "# familiar with it ahead of this demo)\n",
    "\n",
    "data = pd.read_csv('../dataset_1.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 300), (15000, 300))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1), # drop the target\n",
    "    data['target'], # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove constant features\n",
    "\n",
    "First, I will remove constant features like I did in the previous lecture. This will allow a better visualisation of the quasi-constant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 266), (15000, 266))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the code from the previous lecture\n",
    "# I remove 34 constant features\n",
    "\n",
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove quasi-constant features\n",
    "\n",
    "### Using the VarianceThreshold from sklearn\n",
    "\n",
    "The VarianceThreshold from sklearn provides a simple baseline approach to feature selection. It removes all features which variance doesn’t meet a certain threshold. By default, it removes all zero-variance features, as we did in the previous notebook.\n",
    "\n",
    "Here, we will change the default threshold to remove quasi-constant features, or, I should better say, features with low-variance:\n",
    "\n",
    "Check the Scikit-learn docs for more details:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=0.01)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0.01)  \n",
    "\n",
    "sel.fit(X_train)  # fit finds the features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_support is a boolean vector that indicates which features \n",
    "# are retained, that is, which features have a higher variance than\n",
    "# the threshold we indicated.\n",
    "\n",
    "# If we sum over get_support, we get the number\n",
    "# of features that are not quasi-constant\n",
    "\n",
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's print the number of quasi-constant features\n",
    "\n",
    "quasi_constant = X_train.columns[~sel.get_support()]\n",
    "\n",
    "len(quasi_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 51 columns / variables are almost constant. This means that 51 variables show predominantly one value for the majority of observations of the training set. Let's explore a few if these variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var_1', 'var_2', 'var_7', 'var_9', 'var_10', 'var_19', 'var_28',\n",
       "       'var_36', 'var_43', 'var_45', 'var_53', 'var_56', 'var_59', 'var_66',\n",
       "       'var_67', 'var_69', 'var_71', 'var_104', 'var_106', 'var_116',\n",
       "       'var_133', 'var_137', 'var_141', 'var_146', 'var_177', 'var_187',\n",
       "       'var_189', 'var_194', 'var_197', 'var_198', 'var_202', 'var_218',\n",
       "       'var_219', 'var_223', 'var_233', 'var_234', 'var_235', 'var_245',\n",
       "       'var_247', 'var_249', 'var_250', 'var_251', 'var_256', 'var_260',\n",
       "       'var_267', 'var_274', 'var_282', 'var_285', 'var_287', 'var_289',\n",
       "       'var_298'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's print the variable names\n",
    "quasi_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-d5ad38f371c4>:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train['var_1'].value_counts() / np.float(len(X_train))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.999629\n",
       "3    0.000200\n",
       "6    0.000143\n",
       "9    0.000029\n",
       "Name: var_1, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of observations showing each of the different values\n",
    "# of the variable\n",
    "\n",
    "X_train['var_1'].value_counts() / np.float(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that > 99% of the observations show one value, 0. Therefore, this features is fairly constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-e7a55defe18a>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train['var_2'].value_counts() / np.float(len(X_train))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.999971\n",
       "1    0.000029\n",
       "Name: var_2, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore another one\n",
    "\n",
    "X_train['var_2'].value_counts() / np.float(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and explore the rest of the quasi-constant variables.\n",
    "\n",
    "We can then remove the quasi-constant features utilizing the transform() method from the VarianceThreshold. Remember that this returns a NumPy array without feature names, so if we want a dataframe we need to reconstitute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture feature names\n",
    "\n",
    "feat_names = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 215), (15000, 215))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the quasi-constant features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing constant and almost constant features, we reduced the feature space from 300 to 215. This means, that 85 features were removed from this dataset. Almost a third!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_11</th>\n",
       "      <th>var_12</th>\n",
       "      <th>var_13</th>\n",
       "      <th>var_14</th>\n",
       "      <th>var_15</th>\n",
       "      <th>...</th>\n",
       "      <th>var_286</th>\n",
       "      <th>var_288</th>\n",
       "      <th>var_290</th>\n",
       "      <th>var_291</th>\n",
       "      <th>var_292</th>\n",
       "      <th>var_293</th>\n",
       "      <th>var_295</th>\n",
       "      <th>var_296</th>\n",
       "      <th>var_299</th>\n",
       "      <th>var_300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 215 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_3  var_4  var_5  var_6  var_8  var_11  var_12  var_13  var_14  var_15  \\\n",
       "0    0.0   2.79    0.0    0.0    0.0     0.0     0.0     0.0     0.0     3.0   \n",
       "1    0.0   0.00    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2    0.0   2.94    0.0    0.0    0.0     0.0     0.0     0.0     0.0     3.0   \n",
       "3    0.0   2.76    0.0    0.0    0.0     0.0     0.0     0.0     0.0     3.0   \n",
       "4    0.0   2.94    0.0    0.0    0.0     0.0     0.0     0.0     0.0     3.0   \n",
       "\n",
       "   ...  var_286  var_288  var_290  var_291  var_292  var_293  var_295  \\\n",
       "0  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2  ...      0.0      0.0      0.0      0.0      0.0      3.0      0.0   \n",
       "3  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4  ...      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   var_296  var_299  var_300  \n",
       "0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0  \n",
       "4      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 215 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trasnform the array into a dataframe\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=feat_names)\n",
    "X_test = pd.DataFrame(X_test, columns=feat_names)\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding it ourselves\n",
    "\n",
    "First, I will separate the dataset into train and test and remove the constant features again. Then, I will provide an alternative method to find out quasi-constant features.\n",
    "\n",
    "This method, as opposed to the VarianceThreshold, can be used for both **numerical and categorical** variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 266), (15000, 266))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "# remove constant features\n",
    "# using the code from the previous lecture\n",
    "\n",
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an empty list\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# iterate over every feature\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # find the predominant value, that is the value that is shared\n",
    "    # by most observations\n",
    "    predominant = X_train[feature].value_counts(\n",
    "        normalize=True).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # evaluate the predominant feature: do more than 99% of the observations\n",
    "    # show 1 value?\n",
    "    if predominant > 0.998:\n",
    "\n",
    "        # if yes, add the variable to the list\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "len(quasi_constant_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method was a bit more aggressive than VarianceThreshold from sklearn with the threshold that we selected above. It found 108 features that show predominantly 1 value for the majority of the observations. \n",
    "\n",
    "Let's see how some of the quasi constant features look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1',\n",
       " 'var_2',\n",
       " 'var_3',\n",
       " 'var_6',\n",
       " 'var_7',\n",
       " 'var_9',\n",
       " 'var_10',\n",
       " 'var_11',\n",
       " 'var_12',\n",
       " 'var_14',\n",
       " 'var_16',\n",
       " 'var_20',\n",
       " 'var_24',\n",
       " 'var_28',\n",
       " 'var_32',\n",
       " 'var_34',\n",
       " 'var_36',\n",
       " 'var_39',\n",
       " 'var_40',\n",
       " 'var_42',\n",
       " 'var_43',\n",
       " 'var_45',\n",
       " 'var_48',\n",
       " 'var_53',\n",
       " 'var_56',\n",
       " 'var_59',\n",
       " 'var_60',\n",
       " 'var_65',\n",
       " 'var_66',\n",
       " 'var_67',\n",
       " 'var_69',\n",
       " 'var_71',\n",
       " 'var_72',\n",
       " 'var_73',\n",
       " 'var_77',\n",
       " 'var_78',\n",
       " 'var_90',\n",
       " 'var_95',\n",
       " 'var_98',\n",
       " 'var_102',\n",
       " 'var_104',\n",
       " 'var_106',\n",
       " 'var_111',\n",
       " 'var_115',\n",
       " 'var_116',\n",
       " 'var_124',\n",
       " 'var_125',\n",
       " 'var_126',\n",
       " 'var_129',\n",
       " 'var_130',\n",
       " 'var_133',\n",
       " 'var_136',\n",
       " 'var_138',\n",
       " 'var_141',\n",
       " 'var_142',\n",
       " 'var_146',\n",
       " 'var_149',\n",
       " 'var_150',\n",
       " 'var_151',\n",
       " 'var_153',\n",
       " 'var_159',\n",
       " 'var_183',\n",
       " 'var_184',\n",
       " 'var_187',\n",
       " 'var_189',\n",
       " 'var_197',\n",
       " 'var_202',\n",
       " 'var_204',\n",
       " 'var_210',\n",
       " 'var_211',\n",
       " 'var_216',\n",
       " 'var_217',\n",
       " 'var_219',\n",
       " 'var_221',\n",
       " 'var_223',\n",
       " 'var_224',\n",
       " 'var_228',\n",
       " 'var_233',\n",
       " 'var_234',\n",
       " 'var_235',\n",
       " 'var_236',\n",
       " 'var_237',\n",
       " 'var_239',\n",
       " 'var_243',\n",
       " 'var_245',\n",
       " 'var_246',\n",
       " 'var_247',\n",
       " 'var_249',\n",
       " 'var_251',\n",
       " 'var_254',\n",
       " 'var_257',\n",
       " 'var_260',\n",
       " 'var_263',\n",
       " 'var_264',\n",
       " 'var_265',\n",
       " 'var_267',\n",
       " 'var_274',\n",
       " 'var_280',\n",
       " 'var_282',\n",
       " 'var_283',\n",
       " 'var_285',\n",
       " 'var_286',\n",
       " 'var_287',\n",
       " 'var_289',\n",
       " 'var_290',\n",
       " 'var_291',\n",
       " 'var_298',\n",
       " 'var_299']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the feature names\n",
    "\n",
    "quasi_constant_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'var_3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select one feature from the list\n",
    "\n",
    "quasi_constant_feat[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0000         0.999629\n",
       "207901.3365    0.000029\n",
       "15028.0560     0.000029\n",
       "25905.4866     0.000029\n",
       "35685.9459     0.000029\n",
       "3583.3941      0.000029\n",
       "52105.7901     0.000029\n",
       "86718.0000     0.000029\n",
       "861.0900       0.000029\n",
       "2641.0164      0.000029\n",
       "5209.9500      0.000029\n",
       "10281.6000     0.000029\n",
       "12542.3100     0.000029\n",
       "27.3000        0.000029\n",
       "Name: var_3, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['var_3'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature shows 0 for more than 99.9% of the observations. But, it also shows a few different values for a very tiny proportion of the observations. This fact, will increase the feature variance, that is why, this feature is not captured by the VarianceThreshold in our previous cell. Yet, we can see that it is quasi-constant.\n",
    "\n",
    "Keep in mind that the thresholds are arbitrary and decided by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 158), (15000, 158))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally, let's drop the quasi-constant features:\n",
    "\n",
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see, how, we removed almost half of the original variables!!! We passed from 300 variables to 158."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all for this lecture, I hope you enjoyed it and see you in the next one!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsml",
   "language": "python",
   "name": "fsml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
