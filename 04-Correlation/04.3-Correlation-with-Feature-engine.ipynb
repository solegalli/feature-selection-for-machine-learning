{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with Feature-engine\n",
    "\n",
    "- The DropCorrelatedFeatures class from Feature-engine does a similar job to the brute force approach that we described earlier.\n",
    "\n",
    "- The SmartCorrelationSelection allows us to select a feature from each correlated group based on model performance, number of missing values, cardinality or variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 109)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "data = pd.read_csv('../dataset_2.csv', nrows=50000)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>var_107</th>\n",
       "      <th>var_108</th>\n",
       "      <th>var_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.532710</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>17.982476</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.349910</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079066</td>\n",
       "      <td>6.748819</td>\n",
       "      <td>2.941445</td>\n",
       "      <td>18.360496</td>\n",
       "      <td>17.726613</td>\n",
       "      <td>7.774031</td>\n",
       "      <td>1.473441</td>\n",
       "      <td>1.973832</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>2.541417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.821374</td>\n",
       "      <td>12.098722</td>\n",
       "      <td>13.309151</td>\n",
       "      <td>4.125599</td>\n",
       "      <td>1.045386</td>\n",
       "      <td>1.832035</td>\n",
       "      <td>1.833494</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>8.652883</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>7.795290</td>\n",
       "      <td>3.557890</td>\n",
       "      <td>17.383378</td>\n",
       "      <td>15.193423</td>\n",
       "      <td>8.263673</td>\n",
       "      <td>1.878108</td>\n",
       "      <td>0.567939</td>\n",
       "      <td>1.018818</td>\n",
       "      <td>1.416433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938776</td>\n",
       "      <td>7.952752</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>3.459267</td>\n",
       "      <td>1.935782</td>\n",
       "      <td>0.621463</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>0.344948</td>\n",
       "      <td>9.937850</td>\n",
       "      <td>11.691283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861487</td>\n",
       "      <td>6.130886</td>\n",
       "      <td>3.401064</td>\n",
       "      <td>15.850471</td>\n",
       "      <td>14.620599</td>\n",
       "      <td>6.849776</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>1.959183</td>\n",
       "      <td>1.575493</td>\n",
       "      <td>1.857893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.020690</td>\n",
       "      <td>9.900544</td>\n",
       "      <td>17.869637</td>\n",
       "      <td>4.366715</td>\n",
       "      <td>1.973693</td>\n",
       "      <td>2.026012</td>\n",
       "      <td>2.853025</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>11.816859</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340944</td>\n",
       "      <td>7.240058</td>\n",
       "      <td>2.417235</td>\n",
       "      <td>15.194609</td>\n",
       "      <td>13.553772</td>\n",
       "      <td>7.229971</td>\n",
       "      <td>0.835158</td>\n",
       "      <td>2.234482</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>2.700606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.909506</td>\n",
       "      <td>10.576516</td>\n",
       "      <td>0.934191</td>\n",
       "      <td>3.419572</td>\n",
       "      <td>1.871438</td>\n",
       "      <td>3.340811</td>\n",
       "      <td>1.868282</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>13.585620</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>...</td>\n",
       "      <td>2.738095</td>\n",
       "      <td>6.565509</td>\n",
       "      <td>4.341414</td>\n",
       "      <td>15.893832</td>\n",
       "      <td>11.929787</td>\n",
       "      <td>6.954033</td>\n",
       "      <td>1.853364</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>2.599562</td>\n",
       "      <td>0.811364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1      var_2      var_3     var_4     var_5     var_6     var_7  \\\n",
       "0  4.532710   3.280834  17.982476  4.404259  2.349910  0.603264  2.784655   \n",
       "1  5.821374  12.098722  13.309151  4.125599  1.045386  1.832035  1.833494   \n",
       "2  1.938776   7.952752   0.972671  3.459267  1.935782  0.621463  2.338139   \n",
       "3  6.020690   9.900544  17.869637  4.366715  1.973693  2.026012  2.853025   \n",
       "4  3.909506  10.576516   0.934191  3.419572  1.871438  3.340811  1.868282   \n",
       "\n",
       "      var_8      var_9     var_10  ...   var_100   var_101   var_102  \\\n",
       "0  0.323146  12.009691   0.139346  ...  2.079066  6.748819  2.941445   \n",
       "1  0.709090   8.652883   0.102757  ...  2.479789  7.795290  3.557890   \n",
       "2  0.344948   9.937850  11.691283  ...  1.861487  6.130886  3.401064   \n",
       "3  0.674847  11.816859   0.011151  ...  1.340944  7.240058  2.417235   \n",
       "4  0.439865  13.585620   1.153366  ...  2.738095  6.565509  4.341414   \n",
       "\n",
       "     var_103    var_104   var_105   var_106   var_107   var_108   var_109  \n",
       "0  18.360496  17.726613  7.774031  1.473441  1.973832  0.976806  2.541417  \n",
       "1  17.383378  15.193423  8.263673  1.878108  0.567939  1.018818  1.416433  \n",
       "2  15.850471  14.620599  6.849776  1.098210  1.959183  1.575493  1.857893  \n",
       "3  15.194609  13.553772  7.229971  0.835158  2.234482  0.946170  2.700606  \n",
       "4  15.893832  11.929787  6.954033  1.853364  0.511027  2.599562  0.811364  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove correlated\n",
    "\n",
    "### Brute force approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DropCorrelatedFeatures(method='pearson', missing_values='ignore', threshold=0.8,\n",
       "                       variables=['var_1', 'var_2', 'var_3', 'var_4', 'var_5',\n",
       "                                  'var_6', 'var_7', 'var_8', 'var_9', 'var_10',\n",
       "                                  'var_11', 'var_12', 'var_13', 'var_14',\n",
       "                                  'var_15', 'var_16', 'var_17', 'var_18',\n",
       "                                  'var_19', 'var_20', 'var_21', 'var_22',\n",
       "                                  'var_23', 'var_24', 'var_25', 'var_26',\n",
       "                                  'var_27', 'var_28', 'var_29', 'var_30', ...])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the selector\n",
    "\n",
    "sel = DropCorrelatedFeatures(\n",
    "    threshold=0.8,\n",
    "    method='pearson',\n",
    "    missing_values='ignore'\n",
    ")\n",
    "\n",
    "\n",
    "# find correlated features\n",
    "\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'var_3', 'var_80'},\n",
       " {'var_28', 'var_5', 'var_75'},\n",
       " {'var_11', 'var_33'},\n",
       " {'var_13', 'var_17'},\n",
       " {'var_15', 'var_57'},\n",
       " {'var_18', 'var_43'},\n",
       " {'var_19', 'var_29'},\n",
       " {'var_21', 'var_70', 'var_88'},\n",
       " {'var_22', 'var_24', 'var_32', 'var_39', 'var_42', 'var_76'},\n",
       " {'var_102', 'var_23'},\n",
       " {'var_26', 'var_59'},\n",
       " {'var_108', 'var_30'},\n",
       " {'var_35', 'var_87'},\n",
       " {'var_101', 'var_105', 'var_40', 'var_74', 'var_85'},\n",
       " {'var_46', 'var_94'},\n",
       " {'var_50', 'var_72'},\n",
       " {'var_52', 'var_66'},\n",
       " {'var_109', 'var_56'},\n",
       " {'var_104', 'var_60'},\n",
       " {'var_63', 'var_64', 'var_84', 'var_97'},\n",
       " {'var_106', 'var_77'},\n",
       " {'var_90', 'var_95'},\n",
       " {'var_100', 'var_98'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each set contains a group of correlated features\n",
    "\n",
    "sel.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, var_3 is correlated to var_80, and 'var_28', 'var_5', 'var_75' are correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the transformer selects 1 feature from each group.\n",
    "# the rest will be removed and can be found in this attribute\n",
    "\n",
    "len(sel.features_to_drop_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 74), (15000, 74))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop correlated features\n",
    "\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmartCorrelationSelection\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "We will keep a feature from each correlation group based on the performance of a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmartCorrelatedSelection(cv=3,\n",
       "                         estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                          ccp_alpha=0.0,\n",
       "                                                          class_weight=None,\n",
       "                                                          criterion='gini',\n",
       "                                                          max_depth=None,\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          max_samples=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=10,\n",
       "                                                          n_jobs=4,\n",
       "                                                          oob_scor...\n",
       "                         method='pearson', missing_values='raise',\n",
       "                         scoring='roc_auc',\n",
       "                         selection_method='model_performance', threshold=0.8,\n",
       "                         variables=['var_1', 'var_2', 'var_3', 'var_4', 'var_5',\n",
       "                                    'var_6', 'var_7', 'var_8', 'var_9',\n",
       "                                    'var_10', 'var_11', 'var_12', 'var_13',\n",
       "                                    'var_14', 'var_15', 'var_16', 'var_17',\n",
       "                                    'var_18', 'var_19', 'var_20', 'var_21',\n",
       "                                    'var_22', 'var_23', 'var_24', 'var_25',\n",
       "                                    'var_26', 'var_27', 'var_28', 'var_29',\n",
       "                                    'var_30', ...])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    random_state=20,\n",
    "    n_jobs=4,\n",
    ")\n",
    "\n",
    "# correlation selector\n",
    "sel = SmartCorrelatedSelection(\n",
    "    variables=None, # if none, selector examines all numerical variables\n",
    "    method=\"pearson\",\n",
    "    threshold=0.8,\n",
    "    missing_values=\"raise\",\n",
    "    selection_method=\"model_performance\",\n",
    "    estimator=rf,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    ")\n",
    "\n",
    "# this may take a while, because we are training\n",
    "# a random forest per correlation group\n",
    "\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'var_3', 'var_80'},\n",
       " {'var_28', 'var_5', 'var_75'},\n",
       " {'var_11', 'var_33'},\n",
       " {'var_13', 'var_17'},\n",
       " {'var_15', 'var_57'},\n",
       " {'var_18', 'var_43'},\n",
       " {'var_19', 'var_29'},\n",
       " {'var_21', 'var_70', 'var_88'},\n",
       " {'var_22', 'var_24', 'var_32', 'var_39', 'var_42', 'var_76'},\n",
       " {'var_102', 'var_23'},\n",
       " {'var_26', 'var_59'},\n",
       " {'var_108', 'var_30'},\n",
       " {'var_35', 'var_87'},\n",
       " {'var_101', 'var_105', 'var_40', 'var_74', 'var_85'},\n",
       " {'var_46', 'var_94'},\n",
       " {'var_50', 'var_72'},\n",
       " {'var_52', 'var_66'},\n",
       " {'var_109', 'var_56'},\n",
       " {'var_104', 'var_60'},\n",
       " {'var_63', 'var_64', 'var_84', 'var_97'},\n",
       " {'var_106', 'var_77'},\n",
       " {'var_90', 'var_95'},\n",
       " {'var_100', 'var_98'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groups of correlated features\n",
    "\n",
    "sel.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_5 0.4997705830636001\n",
      "var_75 0.5013577660196528\n",
      "var_28 0.506607881644036\n"
     ]
    }
   ],
   "source": [
    "# lets examine the performace of a random forest based on\n",
    "# each feature from the second group, to understand\n",
    "# what the transformer is doing\n",
    "\n",
    "# select second group of correlated features\n",
    "group = sel.correlated_feature_sets_[1]\n",
    "\n",
    "# build random forest with cross validation for\n",
    "# each feature\n",
    "\n",
    "for f in group:\n",
    "    \n",
    "    model = cross_validate(\n",
    "        rf,\n",
    "        X_train[f].to_frame(),\n",
    "        y_train,\n",
    "        cv=3,\n",
    "        return_estimator=False,\n",
    "        scoring='roc_auc',\n",
    "    )\n",
    "\n",
    "    print(f, model[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing feature is var_28, so that one should be retained. The other 2 can be found in the attribute features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retained\n",
    "\n",
    "'var_28' in sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropped\n",
    "\n",
    "'var_5' in sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropped\n",
    "\n",
    "'var_75' in sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance\n",
    "\n",
    "Alternatively, we can select the feature with the highest variance from each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmartCorrelatedSelection(cv=3, estimator=None, method='pearson',\n",
       "                         missing_values='raise', scoring='roc_auc',\n",
       "                         selection_method='variance', threshold=0.8,\n",
       "                         variables=['var_1', 'var_2', 'var_3', 'var_4', 'var_5',\n",
       "                                    'var_6', 'var_7', 'var_8', 'var_9',\n",
       "                                    'var_10', 'var_11', 'var_12', 'var_13',\n",
       "                                    'var_14', 'var_15', 'var_16', 'var_17',\n",
       "                                    'var_18', 'var_19', 'var_20', 'var_21',\n",
       "                                    'var_22', 'var_23', 'var_24', 'var_25',\n",
       "                                    'var_26', 'var_27', 'var_28', 'var_29',\n",
       "                                    'var_30', ...])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation selector\n",
    "\n",
    "sel = SmartCorrelatedSelection(\n",
    "    variables=None,\n",
    "    method=\"pearson\",\n",
    "    threshold=0.8,\n",
    "    missing_values=\"raise\",\n",
    "    selection_method=\"variance\",\n",
    "    estimator=None,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    ")\n",
    "\n",
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var_5     0.875302\n",
       "var_75    3.539938\n",
       "var_28    1.024728\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's examine the variance of the features from the second group of\n",
    "# correlated ones\n",
    "\n",
    "group = sel.correlated_feature_sets_[1]\n",
    "\n",
    "X_train[group].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var_75 has the highest variance, so this feature should be kept and the other ones removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'var_28' in sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'var_5' in sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'var_75' in sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HOMEWORK**\n",
    "\n",
    "Go ahead and try removing by cardinality, which uses the number of unique values of each variable, and then compare the result with pandas nunique().\n",
    "\n",
    "After this, pick another dataset with missing values, and try the method \"missing_values\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fengine",
   "language": "python",
   "name": "fengine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "241.6px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
